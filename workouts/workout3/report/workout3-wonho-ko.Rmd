---
  title: "workout3-wonho-ko"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rvest)
library(xml2)
library(dplyr)
library(stringr)
library(wordcloud)
library(taRifx)
library(tm)
```

```{r}
# Download HTML

# Assemble url (so it fits on screen)
author_url <- "https://raw.githubusercontent.com/ucb-stat133/stat133-fall-2019/master/data/scholar/paul_romer_GoogleScholarCitations.html"

# Download HTML file to your working directory
download.file(author_url, 'Paul Romer_GoogleScholarCitations.html')

# Read the HTML file
parent_data <- read_html('Paul Romer_GoogleScholarCitations.html')

# Assemble url (so it fits on screen)
author_url1 <- "https://raw.githubusercontent.com/ucb-stat133/stat133-fall-2019/master/data/scholar/william_nordhaus_GoogleScholarCitations.html"

# Download HTML file to your working directory
download.file(author_url1, 'William Nordhaus_GoogleScholarCitations.html')

# Read the HTML file
parent_data1 <- read_html('William Nordhaus_GoogleScholarCitations.html')
```

```{r}
#1) Extract simple information of the author

#Paul Romer

author_url = 'https://raw.githubusercontent.com/ucb-stat133/stat133-fall-2019/master/data/scholar/paul_romer_GoogleScholarCitations.html'
citation_page <- read_html(author_url)

info_link <- citation_page %>% html_nodes(xpath ='//*[@id="gsc_a_b"]') %>% 
  html_nodes(xpath ='tr') %>% html_nodes(xpath ='td') 
result = sapply(html_children(info_link), html_text)
result = result[result != '*']

citation_df = data.frame(author = result[seq(2, length(result), 5)],
                         affliated_institution = result[seq(3, length(result), 5)])

citation_df

#William Nordhaus

author_url1 = 'https://raw.githubusercontent.com/ucb-stat133/stat133-fall-2019/master/data/scholar/william_nordhaus_GoogleScholarCitations.html'
citation_page1 <- read_html(author_url1)

info_link1 <- citation_page1 %>% html_nodes(xpath ='//*[@id="gsc_a_b"]') %>% 
  html_nodes(xpath ='tr') %>% html_nodes(xpath ='td') 
result = sapply(html_children(info_link1), html_text)
result = result[result != '*']

citation_df1 = data.frame(author = result[seq(2, length(result), 5)],
                          affliated_institution = result[seq(3, length(result), 5)])

citation_df1
```

```{r}
#2) Extract all the papers for each author (not just the 20 most cited)
Sys.sleep(15)
url1 <- "https://raw.githubusercontent.com/ucb-stat133/stat133-fall-2019/master/data/scholar/paul_romer_GoogleScholarCitations.html"
all_nodes1 <- read_html(url1)
url2 <- "https://raw.githubusercontent.com/ucb-stat133/stat133-fall-2019/master/data/scholar/william_nordhaus_GoogleScholarCitations.html"
all_nodes2 <- read_html(url2)
```

```{r}
#Paul Romer

table_nodes1 <- all_nodes1 %>%
  html_nodes(xpath = '//*[@id="gsc_a_b"]') %>%
  html_nodes(xpath = 'tr') %>%
  html_nodes(xpath = 'td')
children_nodes1 <- html_children(table_nodes1)
children_text1 <- html_text(children_nodes1)
refined_children_text1 <- children_text1[children_text1 != '*']
papers1 <- c(refined_children_text1[seq(from = 1, to = 1126, by = 5)])
authors1 = c(refined_children_text1[seq(from = 2, to = 1127, by = 5)])
journals1 = c(refined_children_text1[seq(from = 3, to = 1128, by = 5)])
citations1 = c(refined_children_text1[seq(from = 4, to = 1129, by = 5)])
years1 = c(refined_children_text1[seq(from = 5, to = 1130, by = 5)])
dat1 <- data.frame("paperName" = papers1, "researcher" = authors1, "journal" = journals1, "citations" = citations1, "year" = years1,stringsAsFactors = FALSE)
dat1
```

```{r}
#William Nordhaus

table_nodes2 <- all_nodes2 %>%
  html_nodes(xpath = '//*[@id="gsc_a_b"]') %>%
  html_nodes(xpath = 'tr') %>%
  html_nodes(xpath = 'td')
result = sapply(html_children(table_nodes2), html_text)
result = result[result != '*']
citation_df = data.frame(paperName = result[seq(1, length(result), 5)],
                         researcher = result[seq(2, length(result), 5)],
                         journal = result[seq(3, length(result), 5)],
                         citations = result[seq(4, length(result), 5)],
                         year = result[seq(5, length(result), 5)])
citation_df
```

```{r}
write.csv (dat1, file = "Paul Romer_GoogleScholarCitations.csv", row.names = FALSE)
write.csv (citation_df, file = "William Nordhaus_GoogleScholarCitations.csv", row.names = FALSE)
```

```{r}
#3) Practice with Regular Expressions
##a
sum(str_detect (dat1$paperName, "^[aeiou]"))
sum(str_detect (citation_df$paperName, "^[aeiou]"))
##b
sum(str_detect (dat1$paperName, "s$"))
sum(str_detect (citation_df$paperName, "s$"))
##c
which.max(str_length(dat1f$paperName))
dat1$paperName[128]
which.max(str_length(citation_df$paperName))
citation_df$paperName[531]
##d

##e
str_replace_all(dat1$paperName, "the|a|an|and|in|if|but|\\.|,|;|\\d", "")
str_replace_all(citation_df$paperName, "the|a|an|and|in|if|but|\\.|,|;|\\d", "")
##f
a <- str_replace_all(dat1$paperName, "the|a|an|and|in|if|but|\\.|,|;|\\d", "")
data.frame((str_split(a, "", simplify = TRUE)), decreasing = TRUE)
##g
b <- str_replace_all(citation_df$paperName, "the|a|an|and|in|if|but|\\.|,|;|\\d", "")
data.frame((str_split(b, "", simplify = TRUE)), decreasing = TRUE)
```

```{r}
#4) Data visualizations
corpus1 <- Corpus(VectorSource(dat1$paperName))
corpus[[1]][1]
corpus1 <- tm_map(corpus, content_transformer(tolower))
corpus1 <- tm_map(corpus, removePunctuation) 
corpus1 <- tm_map(corpus, removeNumbers) 
corpus1 <- tm_map(corpus, removeWords, stopwords("english"))
corpus1 <- tm_map(corpus, stripWhitespace) 
corpus1 <- tm_map(corpus, removeWords, c("the"))
tdm1 <- TermDocumentMatrix(corpus1)
m1 <- as.matrix(tdm1)
v1 <- sort(rowSums(m1), decreasing=TRUE)
d1 <- data.frame(word = names(v1), freq=v1)

wordcloud(dat1$paperName, random.order=FALSE, rot.per=0.1, scale=c(4,.5), max.words=101, colors = brewer.pal(8, "Dark2"))

corpus <- Corpus(VectorSource(citation_df$paperName))
corpus[[1]][1]
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation) 
corpus <- tm_map(corpus, removeNumbers) 
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace) 
corpus <- tm_map(corpus, removeWords, c("the"))
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing=TRUE)
d <- data.frame(word = names(v), freq=v)

wordcloud(citation_df$paperName, random.order=FALSE, rot.per=0.1, scale=c(4,.5), max.words=101, colors = brewer.pal(8, "Dark2"))
```

```{r echo = FALSE, fig.align='center'}
knitr::include_graphics('../images/map-all-stroms.png')
```

```{r}
#5) Report

```








